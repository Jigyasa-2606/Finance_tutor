# -*- coding: utf-8 -*-
"""Untitled99.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DpI3sSurgOq45hBAoPsM0Js_gXWgANo8
"""

from datasets import load_dataset
import re
import pandas as pd

dataset = load_dataset("bilalRahib/fiqa-personal-finance-dataset")
train_dataset = dataset["train"]
df = train_dataset.to_pandas()

def clean(text):
    text = text.strip().replace("\n", " ")
    text = re.sub(r"\s+", " ", text)
    return text

df["input"] = df["input"].apply(clean)
df["output"] = df["output"].apply(clean)

df.to_csv("fiqa_personal_finance_clean.csv", index=False)

df.head()

from transformers import AutoTokenizer

model_name = "google/flan-t5-small"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def preprocess(examples):
    model_inputs = tokenizer(
        examples["input"],
        max_length=256,
        truncation=True,
        padding="max_length"
    )

    labels = tokenizer(
        examples["output"],
        max_length=256,
        truncation=True,
        padding="max_length"
    )

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

tokenized_dataset = dataset.map(preprocess, batched=True)

from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

from transformers import TrainingArguments, Trainer


training_args = TrainingArguments(
    output_dir="./finchatbot",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=50,
    save_total_limit=2
)

dataset_split = tokenized_dataset["train"].train_test_split(test_size=0.1, seed=42)
train_dataset = dataset_split["train"]
eval_dataset = dataset_split["test"]


trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
)


trainer.train()

trainer.save_model("./finchatbot-final")
tokenizer.save_pretrained("./finchatbot-final")

from transformers import pipeline

chatbot = pipeline("text2text-generation", model="./finchatbot-final", tokenizer=tokenizer)

test_input = "What is a mutual fund?"
response = chatbot(test_input, max_length=100, do_sample=True, top_p=0.9, temperature=0.7, early_stopping=True,repetition_penalty=2.5)
print("Predicted Answer:", response[0]['generated_text'])

!pip install evaluate

!pip install rouge_score

import evaluate
import pandas as pd

rouge = evaluate.load("rouge")

preds, refs = [], []

for i in range(50):
    input_text = eval_dataset[i]["input"]
    ref_text = eval_dataset[i]["output"]

    pred = chatbot(input_text, max_length=500, do_sample=False)[0]['generated_text']

    preds.append(pred)
    refs.append(ref_text)

results = rouge.compute(predictions=preds, references=refs)
print(results)

import pandas as pd
from datasets import Dataset
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer

df2 = pd.read_csv("/content/wandb/final.csv", quoting=3, on_bad_lines="skip").fillna("")


dataset = Dataset.from_pandas(df2)

model_name = "google/flan-t5-small"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def preprocess(examples):
    model_inputs = tokenizer(
        [str(x) for x in examples["input"]],
        max_length=256,
        truncation=True,
        padding="max_length"
    )

    labels = tokenizer(
        [str(x) for x in examples["output"]],
        max_length=256,
        truncation=True,
        padding="max_length"
    )

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

tokenized_dataset = dataset.map(preprocess, batched=True)

dataset_split = tokenized_dataset.train_test_split(test_size=0.1, seed=42)
train_dataset = dataset_split["train"]
eval_dataset = dataset_split["test"]


model = AutoModelForSeq2SeqLM.from_pretrained(model_name)


training_args = TrainingArguments(
    output_dir="./finchatbot2",
    save_strategy="epoch",
    learning_rate=5e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=50,
    save_total_limit=2
)


trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    tokenizer=tokenizer,
)


trainer.train()

import yfinance as yf

def get_stock_info(ticker_symbol):
    try:
        stock = yf.Ticker(ticker_symbol)
        hist = stock.history(period="1d")
        latest_price = hist["Close"].iloc[-1]
        info = stock.info

        return (
            f"{ticker_symbol.upper()} Stock Info:\n"
            f"Price: {latest_price:.2f} USD\n"
            f" Market Cap: {info.get('marketCap')}\n"
            f" P/E Ratio: {info.get('trailingPE')}\n"
            f" EPS: {info.get('trailingEps')}"
        )
    except Exception as e:
        return f" Error fetching data for {ticker_symbol}: {e}"

def chatbot():
    print("StockBot: Hi! Ask me about any stock (e.g., AAPL, TSLA, MSFT). Type 'quit' to exit.")
    while True:
        user_input = input("You: ").strip()
        if user_input.lower() == "quit":
            print(" StockBot: Goodbye!")
            break
        else:
            response = get_stock_info(user_input)
            print(response)


if __name__ == "__main__":
    chatbot()